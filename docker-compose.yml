include:
  - path: supabase/docker-compose.yml
    env_file:
      - .env

services:
  # This service runs the gRPC server that loads your user code, in both dagster-webserver
  # and dagster-daemon. By setting DAGSTER_CURRENT_IMAGE to its own image, we tell the
  # run launcher to use this same image when launching runs in a new container as well.
  # Multiple containers like this can be deployed separately - each just needs to run on
  # its own port, and have its own entry in the workspace.yaml file that's loaded by the
  # webserver.
  mdharura_etl_runner:
    build:
      context: .
      dockerfile: ./Dockerfile.etl
    container_name: mdharura_etl_runner
    image: mdharura_etl_runner
    restart: always
    depends_on:
      db:
        condition: service_healthy
    environment:
      DAGSTER_POSTGRES_USER: ${POSTGRES_USER}
      DAGSTER_POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      DAGSTER_POSTGRES_DB: ${POSTGRES_DB}
      DAGSTER_POSTGRES_HOST: ${ETL_POSTGRES_HOST}
      DAGSTER_POSTGRES_PORT: ${POSTGRES_BIND_PORT}
      DAGSTER_CURRENT_IMAGE: "mdharura_etl_runner"
      DBT_SERVER_DEV: ${ETL_POSTGRES_HOST}
      DBT_DATABASE_DEV: ${POSTGRES_DB}
      DBT_SCHEMA: "mdharura_dbt"
      DBT_PORT_DEV: ${POSTGRES_BIND_PORT}
      DBT_USER_DEV: ${POSTGRES_USER}
      DBT_PASSWORD_DEV: ${POSTGRES_PASSWORD}
      SOURCES__MONGODB__CONNECTION__URL: ${SOURCES__MONGODB__CONNECTION__URL}
      DESTINATION__POSTGRES__CREDENTIALS__DATABASE: ${POSTGRES_DB}
      DESTINATION__POSTGRES__CREDENTIALS__PASSWORD: ${POSTGRES_PASSWORD}
      DESTINATION__POSTGRES__CREDENTIALS__USERNAME: ${POSTGRES_USER}
      DESTINATION__POSTGRES__CREDENTIALS__HOST: ${ETL_POSTGRES_HOST}
      DESTINATION__POSTGRES__CREDENTIALS__PORT: ${POSTGRES_BIND_PORT}
      DESTINATION__POSTGRES__CREDENTIALS__CONNECT_TIMEOUT: "15"
    network_mode: host
    extra_hosts:
      - "host.docker.internal:host-gateway"
    volumes:
      - ./etl/definitions.py:/opt/dagster/app/definitions.py
      - ./etl/assets.py:/opt/dagster/app/assets.py
      - ./etl/project.py:/opt/dagster/app/project.py
      - ./etl/dagster.yaml:/opt/dagster/app/dagster.yaml
      - ./etl/workspace.yaml:/opt/dagster/app/workspace.yaml
    limits:
      memory: 500M

  # This service runs dagster-webserver, which loads your user code from the user code container.
  # Since our instance uses the QueuedRunCoordinator, any runs submitted from the webserver will be put on
  # a queue and later dequeued and launched by dagster-daemon.
  mdharura_etl_webserver:
    build:
      context: .
      dockerfile: ./Dockerfile.dagster
    entrypoint:
      - dagster-webserver
      - -h
      - "0.0.0.0"
      - -p
      - "${DAGSTER_WEB_PORT}"
      - -w
      - workspace.yaml
    container_name: mdharura_etl_webserver
    image: mdharura_etl_webserver
    network_mode: host
    environment:
      DAGSTER_POSTGRES_USER: ${POSTGRES_USER}
      DAGSTER_POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      DAGSTER_POSTGRES_DB: ${POSTGRES_DB}
      DAGSTER_POSTGRES_HOST: ${ETL_POSTGRES_HOST}
      DAGSTER_POSTGRES_PORT: ${POSTGRES_BIND_PORT}
      DBT_SERVER_DEV: ${ETL_POSTGRES_HOST}
      DBT_DATABASE_DEV: ${POSTGRES_DB}
      DBT_SCHEMA: "mdharura_dbt"
      DBT_PORT_DEV: ${POSTGRES_BIND_PORT}
      DBT_USER_DEV: ${POSTGRES_USER}
      DBT_PASSWORD_DEV: ${POSTGRES_PASSWORD}
      SOURCES__MONGODB__CONNECTION__URL: ${SOURCES__MONGODB__CONNECTION__URL}
      DESTINATION__POSTGRES__CREDENTIALS__DATABASE: ${POSTGRES_DB}
      DESTINATION__POSTGRES__CREDENTIALS__PASSWORD: ${POSTGRES_PASSWORD}
      DESTINATION__POSTGRES__CREDENTIALS__USERNAME: ${POSTGRES_USER}
      DESTINATION__POSTGRES__CREDENTIALS__HOST: ${ETL_POSTGRES_HOST}
      DESTINATION__POSTGRES__CREDENTIALS__PORT: ${POSTGRES_BIND_PORT}
      DESTINATION__POSTGRES__CREDENTIALS__CONNECT_TIMEOUT: "15"

    volumes: # Make docker client accessible so we can terminate containers from the webserver
      - /var/run/docker.sock:/var/run/docker.sock
      - ${DAGSTER_VOLUME}:/tmp/io_manager_storage
    depends_on:
      db:
        condition: service_healthy
      mdharura_etl_runner:
        condition: service_started
    extra_hosts:
      - "host.docker.internal:host-gateway"
    limits:
      memory: 1000M

  # This service runs the dagster-daemon process, which is responsible for taking runs
  # off of the queue and launching them, as well as creating runs from schedules or sensors.
  mdharura_etl_daemon:
    build:
      context: .
      dockerfile: ./Dockerfile.dagster
    entrypoint:
      - dagster-daemon
      - run
    container_name: mdharura_etl_daemon
    image: mdharura_etl_daemon
    restart: on-failure
    environment:
      DAGSTER_POSTGRES_USER: ${POSTGRES_USER}
      DAGSTER_POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      DAGSTER_POSTGRES_DB: ${POSTGRES_DB}
      DAGSTER_POSTGRES_PORT: ${POSTGRES_BIND_PORT}
      DAGSTER_POSTGRES_HOST: ${ETL_POSTGRES_HOST}
      DBT_SERVER_DEV: ${ETL_POSTGRES_HOST}
      DBT_DATABASE_DEV: ${POSTGRES_DB}
      DBT_SCHEMA: "mdharura_dbt"
      DBT_PORT_DEV: ${POSTGRES_BIND_PORT}
      DBT_USER_DEV: ${POSTGRES_USER}
      DBT_PASSWORD_DEV: ${POSTGRES_PASSWORD}
      SOURCES__MONGODB__CONNECTION__URL: ${SOURCES__MONGODB__CONNECTION__URL}
      DESTINATION__POSTGRES__CREDENTIALS__DATABASE: ${POSTGRES_DB}
      DESTINATION__POSTGRES__CREDENTIALS__PASSWORD: ${POSTGRES_PASSWORD}
      DESTINATION__POSTGRES__CREDENTIALS__USERNAME: ${POSTGRES_USER}
      DESTINATION__POSTGRES__CREDENTIALS__HOST: ${ETL_POSTGRES_HOST}
      DESTINATION__POSTGRES__CREDENTIALS__PORT: ${POSTGRES_BIND_PORT}
      DESTINATION__POSTGRES__CREDENTIALS__CONNECT_TIMEOUT: "15"

    volumes: # Make docker client accessible so we can launch containers using host docker
      - /var/run/docker.sock:/var/run/docker.sock
      - ${DAGSTER_VOLUME}:/tmp/io_manager_storage
    network_mode: host
    depends_on:
      db:
        condition: service_healthy
      mdharura_etl_runner:
        condition: service_started
    extra_hosts:
      - "host.docker.internal:host-gateway"
    limits:
      memory: 500M

networks:
  mdharura_etl_network:
    driver: bridge
    name: mdharura_etl_network
